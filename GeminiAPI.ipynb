{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini API 實作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 前言\n",
    "\n",
    "前面講了這麼多，其實是在跟大家講解API的實際工作原理。<br/>\n",
    "Google generative AI 的套件已經將整個APIc calling 的操作整合，大家不用擔心操作複雜。<br/>\n",
    "那麼接下來我們就來實作一個簡單的API calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 預先下載套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (2.154.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (5.29.1)\n",
      "Requirement already satisfied: pydantic in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Config API 金鑰及指定模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=\"YOUR_API_KEY\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate content 生成文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"AI has a vast range of applications, impacting nearly every aspect of modern life.  Here are some examples categorized for clarity:\\n\\n**Creative & Entertainment:**\\n\\n* **Generating text:** Write stories, poems, scripts, articles, marketing copy, and more. Tools like ChatGPT and Jasper are examples.\\n* **Creating images:** Generate unique artwork, illustrations, logos, and photorealistic images from text descriptions using tools like Midjourney, DALL-E 2, and Stable Diffusion.\\n* **Composing music:** Create original musical pieces in various styles.\\n* **Editing video and audio:** Enhance video quality, add special effects, and improve audio clarity.  AI can also assist in creating realistic deepfakes (though ethically questionable in many applications).\\n* **Playing games:** AI powers opponents in video games, offering increasingly challenging and realistic gameplay.\\n\\n\\n**Productivity & Business:**\\n\\n* **Automating tasks:** Streamline repetitive tasks like scheduling emails, managing calendars, data entry, and customer service responses.\\n* **Data analysis:** Identify trends, patterns, and insights in large datasets to inform business decisions.\\n* **Customer service:** Provide instant support through chatbots and virtual assistants.\\n* **Marketing and sales:** Personalize marketing campaigns, predict customer behavior, and optimize sales strategies.\\n* **Project management:** Help organize tasks, track progress, and manage resources.\\n* **Translation:** Translate text and speech between multiple languages.\\n\\n\\n**Science & Technology:**\\n\\n* **Medical diagnosis:** Assist doctors in diagnosing diseases and recommending treatments.\\n* **Drug discovery:** Accelerate the process of developing new drugs and therapies.\\n* **Climate modeling:** Predict climate change impacts and develop mitigation strategies.\\n* **Robotics:** Control robots for tasks like manufacturing, surgery, and exploration.\\n* **Space exploration:** Analyze data from space missions and control robotic probes.\\n\\n\\n**Personal Use:**\\n\\n* **Smart assistants:** Control smart home devices, set reminders, answer questions, and provide information.  Examples include Siri, Alexa, and Google Assistant.\\n* **Personalized recommendations:** Receive customized recommendations for movies, music, books, and products.\\n* **Language learning:** Use AI-powered language learning apps to improve your language skills.\\n\\n\\n**Ethical Considerations:**  It's crucial to be aware of the ethical implications of AI, including:\\n\\n* **Bias:** AI systems can reflect and amplify biases present in the data they are trained on.\\n* **Privacy:** AI systems often collect and process large amounts of personal data.\\n* **Job displacement:** Automation driven by AI could lead to job losses in some sectors.\\n* **Misinformation:** AI can be used to create and spread misinformation.\\n\\n\\nThis is not an exhaustive list, but it provides a broad overview of what you can do with AI.  The possibilities are constantly expanding as the technology continues to evolve.  The best way to explore what AI can do for you is to identify a specific problem or task and then search for AI tools or services designed to address it.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.21720535623988674\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 8,\n",
      "        \"candidates_token_count\": 618,\n",
      "        \"total_token_count\": 626\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"What can i do with ai?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看重點回覆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI has a vast range of applications, impacting nearly every aspect of modern life.  Here are some examples categorized for clarity:\n",
      "\n",
      "**Creative & Entertainment:**\n",
      "\n",
      "* **Generating text:** Write stories, poems, scripts, articles, marketing copy, and more. Tools like ChatGPT and Jasper are examples.\n",
      "* **Creating images:** Generate unique artwork, illustrations, logos, and photorealistic images from text descriptions using tools like Midjourney, DALL-E 2, and Stable Diffusion.\n",
      "* **Composing music:** Create original musical pieces in various styles.\n",
      "* **Editing video and audio:** Enhance video quality, add special effects, and improve audio clarity.  AI can also assist in creating realistic deepfakes (though ethically questionable in many applications).\n",
      "* **Playing games:** AI powers opponents in video games, offering increasingly challenging and realistic gameplay.\n",
      "\n",
      "\n",
      "**Productivity & Business:**\n",
      "\n",
      "* **Automating tasks:** Streamline repetitive tasks like scheduling emails, managing calendars, data entry, and customer service responses.\n",
      "* **Data analysis:** Identify trends, patterns, and insights in large datasets to inform business decisions.\n",
      "* **Customer service:** Provide instant support through chatbots and virtual assistants.\n",
      "* **Marketing and sales:** Personalize marketing campaigns, predict customer behavior, and optimize sales strategies.\n",
      "* **Project management:** Help organize tasks, track progress, and manage resources.\n",
      "* **Translation:** Translate text and speech between multiple languages.\n",
      "\n",
      "\n",
      "**Science & Technology:**\n",
      "\n",
      "* **Medical diagnosis:** Assist doctors in diagnosing diseases and recommending treatments.\n",
      "* **Drug discovery:** Accelerate the process of developing new drugs and therapies.\n",
      "* **Climate modeling:** Predict climate change impacts and develop mitigation strategies.\n",
      "* **Robotics:** Control robots for tasks like manufacturing, surgery, and exploration.\n",
      "* **Space exploration:** Analyze data from space missions and control robotic probes.\n",
      "\n",
      "\n",
      "**Personal Use:**\n",
      "\n",
      "* **Smart assistants:** Control smart home devices, set reminders, answer questions, and provide information.  Examples include Siri, Alexa, and Google Assistant.\n",
      "* **Personalized recommendations:** Receive customized recommendations for movies, music, books, and products.\n",
      "* **Language learning:** Use AI-powered language learning apps to improve your language skills.\n",
      "\n",
      "\n",
      "**Ethical Considerations:**  It's crucial to be aware of the ethical implications of AI, including:\n",
      "\n",
      "* **Bias:** AI systems can reflect and amplify biases present in the data they are trained on.\n",
      "* **Privacy:** AI systems often collect and process large amounts of personal data.\n",
      "* **Job displacement:** Automation driven by AI could lead to job losses in some sectors.\n",
      "* **Misinformation:** AI can be used to create and spread misinformation.\n",
      "\n",
      "\n",
      "This is not an exhaustive list, but it provides a broad overview of what you can do with AI.  The possibilities are constantly expanding as the technology continues to evolve.  The best way to explore what AI can do for you is to identify a specific problem or task and then search for AI tools or services designed to address it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 圖片生成文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下載 圖片讀取套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in d:\\miniconda\\envs\\mcsh_course\\lib\\site-packages (11.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m pic_response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     10\u001b[0m pic \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(BytesIO(pic_response\u001b[38;5;241m.\u001b[39mcontent)) \u001b[38;5;66;03m# 大家不用理解這一行，只需要知道他是讀取圖片的方法\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me about this picture\u001b[39m\u001b[38;5;124m\"\u001b[39m, pic],stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\generativeai\\generative_models.py:325\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mrewrite_stream_error():\n\u001b[1;32m--> 325\u001b[0m         iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mstream_generate_content(\n\u001b[0;32m    326\u001b[0m             request,\n\u001b[0;32m    327\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    328\u001b[0m         )\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:1134\u001b[0m, in \u001b[0;36mGenerativeServiceClient.stream_generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1134\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m   1135\u001b[0m     request,\n\u001b[0;32m   1136\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m   1137\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1138\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m   1139\u001b[0m )\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:170\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Auto-fetching the first result causes PubSub client's streaming pull\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# to hang when re-opening the stream, thus we need examine the hacky\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# hidden flag to see if pre-fetching is disabled.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/googleapis/python-pubsub/issues/93#issuecomment-630762257\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     prefetch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callable_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_prefetch_first_result_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[0;32m    171\u001b[0m         result, prefetch_first_result\u001b[38;5;241m=\u001b[39mprefetch_first\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:92\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__init__\u001b[1;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefetch_first_result:\n\u001b[1;32m---> 92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_first_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# It is possible the wrapped method isn't an iterable (a grpc.Call\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# for instance). If this happens don't store the first result.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\grpc\\_channel.py:543\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next()\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\grpc\\_channel.py:960\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    956\u001b[0m         cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue\n\u001b[0;32m    957\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    958\u001b[0m     )\n\u001b[1;32m--> 960\u001b[0m _common\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcondition\u001b[38;5;241m.\u001b[39mwait, _response_ready)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\grpc\\_common.py:156\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_complete_fn():\n\u001b[1;32m--> 156\u001b[0m         _wait_once(wait_fn, MAXIMUM_WAIT_TIMEOUT, spin_cb)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m timeout\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\site-packages\\grpc\\_common.py:116\u001b[0m, in \u001b[0;36m_wait_once\u001b[1;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_once\u001b[39m(\n\u001b[0;32m    112\u001b[0m     wait_fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mbool\u001b[39m],\n\u001b[0;32m    113\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    114\u001b[0m     spin_cb: Optional[Callable[[], \u001b[38;5;28;01mNone\u001b[39;00m]],\n\u001b[0;32m    115\u001b[0m ):\n\u001b[1;32m--> 116\u001b[0m     wait_fn(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spin_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m         spin_cb()\n",
      "File \u001b[1;32md:\\miniconda\\envs\\mcsh_course\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "url = 'https://preview.redd.it/r3cd5lf88yj81.png?auto=webp&s=2169f23199e99445ab2cee153771ee653b313603' # 這是一張圖片的網址\n",
    "pic_response = requests.get(url)\n",
    "pic = Image.open(BytesIO(pic_response.content)) # 大家不用理解這一行，只需要知道他是讀取圖片的方法\n",
    "\n",
    "\n",
    "response = model.generate_content([\"Tell me about this picture\", pic],stream=True)\n",
    "for i in response:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 參數調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\n",
    "    'tell me something about the previous picture',\n",
    "    generation_config = genai.GenerationConfig(max_output_tokens=1000,temperature=0.1,),\n",
    "    stream=False\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_output_tokens: 生成文字的最大長度\n",
    "- temperature: 創意度，0.1~ 2.0 ，數字越高創意度越高\n",
    "- top_k: 決定取幾個機率最高的前幾個字。\n",
    "- top_p: 取機率最高的前幾個字，數字越大創意度越高\n",
    "- frequency_penalty: 決定重複字詞的機率\n",
    "<br/>\n",
    "......太多了，大家可以參考官方文件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Chat mode 聊天模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面的模式讓我們可以生成文字，但是不會產生聊天紀錄，每次的對話都是單次的<br/>\n",
    "但是如果我們想要持續的跟AI對話呢？<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message(\"HI\")\n",
    "print(response.text)\n",
    "\n",
    "\n",
    "msg = \"Something to ask AI\"\n",
    "print(\"User:\\n\",msg)\n",
    "response = chat.send_message(f'{msg}')\n",
    "print(\"AI:\")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用stream 方法來逐一地顯示輸出，減少時間斷裂感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message(\"HI\")\n",
    "print(response.text)\n",
    "try:\n",
    "    while(True):\n",
    "        msg = input(\"\")\n",
    "        print(\"User:\\n\",msg)\n",
    "        response = chat.send_message(f'{msg}',stream=True)\n",
    "        print(\"AI:\")\n",
    "        for chunck in response:\n",
    "            print(chunck.text)\n",
    "except:\n",
    "    print (\"Chat ended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 程式碼執行模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini API 可以直接執行的程式碼，大家可以直接執行看看結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To answer your question, I need to first generate the first 50 prime numbers and then calculate their sum.  I'll use a function to identify primes and then iterate to find the first 50.\n",
      "\n",
      "\n",
      "``` python\n",
      "def is_prime(n):\n",
      "    \"\"\"Checks if a number is prime.\"\"\"\n",
      "    if n <= 1:\n",
      "        return False\n",
      "    if n <= 3:\n",
      "        return True\n",
      "    if n % 2 == 0 or n % 3 == 0:\n",
      "        return False\n",
      "    i = 5\n",
      "    while i * i <= n:\n",
      "        if n % i == 0 or n % (i + 2) == 0:\n",
      "            return False\n",
      "        i += 6\n",
      "    return True\n",
      "\n",
      "primes = []\n",
      "num = 2\n",
      "count = 0\n",
      "while count < 50:\n",
      "    if is_prime(num):\n",
      "        primes.append(num)\n",
      "        count += 1\n",
      "    num += 1\n",
      "\n",
      "print(f'{primes=}')\n",
      "print(f'Sum of the first 50 prime numbers: {sum(primes)}')\n",
      "\n",
      "\n",
      "```\n",
      "```\n",
      "primes=[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229]\n",
      "Sum of the first 50 prime numbers: 5117\n",
      "\n",
      "```\n",
      "The code generates the first 50 prime numbers and calculates their sum. The sum of the first 50 prime numbers is 5117.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name='gemini-1.5-flash')\n",
    "\n",
    "response = model.generate_content(('What is the sum of the first 50 prime numbers? '\n",
    "    'Generate and run code for the calculation, and make sure you get all 50.'),\n",
    "    tools='code_execution')\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To answer your question, I need to first generate the first 50 prime numbers and then calculate their sum.  I'll use a function to identify primes and then iterate to find the first 50.\n",
       "\n",
       "\n",
       "``` python\n",
       "def is_prime(n):\n",
       "    \"\"\"Checks if a number is prime.\"\"\"\n",
       "    if n <= 1:\n",
       "        return False\n",
       "    if n <= 3:\n",
       "        return True\n",
       "    if n % 2 == 0 or n % 3 == 0:\n",
       "        return False\n",
       "    i = 5\n",
       "    while i * i <= n:\n",
       "        if n % i == 0 or n % (i + 2) == 0:\n",
       "            return False\n",
       "        i += 6\n",
       "    return True\n",
       "\n",
       "primes = []\n",
       "num = 2\n",
       "count = 0\n",
       "while count < 50:\n",
       "    if is_prime(num):\n",
       "        primes.append(num)\n",
       "        count += 1\n",
       "    num += 1\n",
       "\n",
       "print(f'{primes=}')\n",
       "print(f'Sum of the first 50 prime numbers: {sum(primes)}')\n",
       "\n",
       "\n",
       "```\n",
       "```\n",
       "primes=[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229]\n",
       "Sum of the first 50 prime numbers: 5117\n",
       "\n",
       "```\n",
       "The code generates the first 50 prime numbers and calculates their sum. The sum of the first 50 prime numbers is 5117.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當然，也可以將Code Execution 寫成對話形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "model = genai.GenerativeModel(model_name='gemini-1.5-pro',\n",
    "                              tools='code_execution')\n",
    "\n",
    "chat = model.start_chat()\n",
    "\n",
    "response = chat.send_message((\n",
    "    'What is the sum of the first 50 prime numbers? '\n",
    "    'Generate and run code for the calculation, and make sure you get all 50.'))\n",
    "\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcsh_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
