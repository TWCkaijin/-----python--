{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini API 實作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 前言\n",
    "\n",
    "前面講了這麼多，其實是在跟大家講解API的實際工作原理。<br/>\n",
    "Google generative AI 的套件已經將整個APIc calling 的操作整合，大家不用擔心操作複雜。<br/>\n",
    "那麼接下來我們就來實作一個簡單的API calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 預先下載套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Config API 金鑰及指定模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"YOUR_API_KEY\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate content 生成文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"What can i do with ai?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看重點回覆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 圖片生成文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下載 圖片讀取套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "url = 'https://preview.redd.it/r3cd5lf88yj81.png?auto=webp&s=2169f23199e99445ab2cee153771ee653b313603' # 這是一張圖片的網址\n",
    "pic_response = requests.get(url)\n",
    "pic = Image.open(BytesIO(pic_response.content)) # 大家不用理解這一行，只需要知道他是讀取圖片的方法\n",
    "\n",
    "\n",
    "response = model.generate_content([\"Tell me about this picture\", pic],stream=True)\n",
    "for i in response:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 參數調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\n",
    "    'tell me something about the previous picture',\n",
    "    generation_config = genai.GenerationConfig(max_output_tokens=1000,temperature=0.1,),\n",
    "    stream=False\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_output_tokens: 生成文字的最大長度\n",
    "- temperature: 創意度，0.1~ 2.0 ，數字越高創意度越高\n",
    "- top_k: 決定取幾個機率最高的前幾個字。\n",
    "- top_p: 取機率最高的前幾個字，數字越大創意度越高\n",
    "- frequency_penalty: 決定重複字詞的機率\n",
    "<br/>\n",
    "......太多了，大家可以參考官方文件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Chat mode 聊天模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面的模式讓我們可以生成文字，但是不會產生聊天紀錄，每次的對話都是單次的<br/>\n",
    "但是如果我們想要持續的跟AI對話呢？<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message(\"HI\")\n",
    "print(response.text)\n",
    "try:\n",
    "    while(True):\n",
    "        msg = input(\"\")\n",
    "        response = chat.send_message(f'{msg}',stream=True)\n",
    "        for chunck in response:\n",
    "            print(chunck.text)\n",
    "except:\n",
    "    print (\"Chat ended\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcsh_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
